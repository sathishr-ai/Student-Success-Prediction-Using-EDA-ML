{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu2cuOpVFNB7",
        "outputId": "7099c8d4-fefe-4eea-983f-1b65697fa8bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with shape: (1200, 14)\n",
            "Columns: ['StudentID', 'Gender', 'Age', 'SchoolType', 'ParentalEducation', 'StudyHours', 'AttendancePercent', 'ExtraClasses', 'InternetAccess', 'PreviousScore', 'TestPrepCourse', 'SocioeconomicStatus', 'Score', 'Pass']\n",
            "Using target column: 'Pass'\n",
            "\n",
            "-- Basic EDA --\n",
            "Shape: (1200, 14)\n",
            "                      count unique        top  freq       mean        std  \\\n",
            "StudentID              1200   1200  STUD11183     1        NaN        NaN   \n",
            "Gender                 1200      3     Female   602        NaN        NaN   \n",
            "Age                  1200.0    NaN        NaN   NaN  16.555833     1.7086   \n",
            "SchoolType             1200      2     Public   824        NaN        NaN   \n",
            "ParentalEducation      1200      5   Bachelor   363        NaN        NaN   \n",
            "StudyHours           1200.0    NaN        NaN   NaN   3.547667   1.896068   \n",
            "AttendancePercent    1200.0    NaN        NaN   NaN   84.64375   9.524886   \n",
            "ExtraClasses           1200      2         No   784        NaN        NaN   \n",
            "InternetAccess         1200      2        Yes  1054        NaN        NaN   \n",
            "PreviousScore        1200.0    NaN        NaN   NaN  64.383083  14.859416   \n",
            "TestPrepCourse         1200      1  Completed  1200        NaN        NaN   \n",
            "SocioeconomicStatus    1200      3     Middle   720        NaN        NaN   \n",
            "Score                1200.0    NaN        NaN   NaN  67.137333  13.007291   \n",
            "Pass                 1200.0    NaN        NaN   NaN   0.904167   0.294485   \n",
            "\n",
            "                      min     25%    50%     75%    max  \n",
            "StudentID             NaN     NaN    NaN     NaN    NaN  \n",
            "Gender                NaN     NaN    NaN     NaN    NaN  \n",
            "Age                  14.0    15.0   17.0    18.0   19.0  \n",
            "SchoolType            NaN     NaN    NaN     NaN    NaN  \n",
            "ParentalEducation     NaN     NaN    NaN     NaN    NaN  \n",
            "StudyHours            0.0     2.2    3.5     4.8   10.8  \n",
            "AttendancePercent    47.9    77.7   85.2  92.025  100.0  \n",
            "ExtraClasses          NaN     NaN    NaN     NaN    NaN  \n",
            "InternetAccess        NaN     NaN    NaN     NaN    NaN  \n",
            "PreviousScore        20.0  54.375  64.55    74.5  100.0  \n",
            "TestPrepCourse        NaN     NaN    NaN     NaN    NaN  \n",
            "SocioeconomicStatus   NaN     NaN    NaN     NaN    NaN  \n",
            "Score                28.0    58.7   67.2    76.1  100.0  \n",
            "Pass                  0.0     1.0    1.0     1.0    1.0  \n",
            "Cleaned data saved to: outputs/cleaned_student_data.csv\n",
            "Final feature matrix shape: (1200, 16)\n",
            "\n",
            "Model Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        29\n",
            "           1       1.00      1.00      1.00       271\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       1.00      1.00      1.00       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "Saved predictions sample to outputs/predictions_sample.csv\n",
            "\n",
            "Done. Check the 'outputs' folder for images and CSV files.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set(style=\"whitegrid\")\n",
        "DATA_FILE = \"student_performance.csv\"\n",
        "OUTPUT_DIR = \"outputs\"\n",
        "def safe_mkdir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "def load_data(path):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"File not found: {path}. Put your CSV in the same folder as this script.\")\n",
        "    df = pd.read_csv(path)\n",
        "    return df\n",
        "def clean_and_fill(df):\n",
        "    # Drop exact duplicate rows if any\n",
        "    df = df.drop_duplicates().reset_index(drop=True)\n",
        "    # Lower/strip column names for safer checks, keep original mapping\n",
        "    cols = {c: c.strip() for c in df.columns}\n",
        "    df.rename(columns=cols, inplace=True)\n",
        "    # Replace empty strings with NaN\n",
        "    df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
        "    # Fill numeric columns with mean, categorical with mode\n",
        "    for col in df.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            if df[col].isnull().any():\n",
        "                df[col].fillna(df[col].mean(), inplace=True)\n",
        "        else:\n",
        "            if df[col].isnull().any():\n",
        "                try:\n",
        "                    df[col].fillna(df[col].mode(dropna=True)[0], inplace=True)\n",
        "                except Exception:\n",
        "                    df[col].fillna(\"Unknown\", inplace=True)\n",
        "    return df\n",
        "\n",
        "def infer_target(df):\n",
        "    # Prefer existing Pass column (case-insensitive)\n",
        "    pass_col = None\n",
        "    for candidate in [\"Pass\", \"pass\", \"PASS\"]:\n",
        "        if candidate in df.columns:\n",
        "            pass_col = candidate\n",
        "            break\n",
        "    if pass_col:\n",
        "        df['Pass'] = df[pass_col].apply(lambda x: int(x) if (str(x).strip() != \"\") else 0)\n",
        "        return df, 'Pass'\n",
        "\n",
        "    # If Score exists, create Pass with threshold 50\n",
        "    if 'Score' in df.columns:\n",
        "        df['Pass'] = (pd.to_numeric(df['Score'], errors='coerce').fillna(0) >= 50).astype(int)\n",
        "        return df, 'Pass'\n",
        "\n",
        "    # If neither exists, ask user to create a target manually\n",
        "    raise ValueError(\"No 'Pass' or 'Score' column found. Please include a 'Score' column or a 'Pass' (0/1) column in the CSV.\")\n",
        "\n",
        "def basic_eda_and_save(df):\n",
        "    safe_mkdir(OUTPUT_DIR)\n",
        "    print(\"\\n-- Basic EDA --\")\n",
        "    print(\"Shape:\", df.shape)\n",
        "    print(df.describe(include='all').T)\n",
        "    # Score distribution (if present)\n",
        "    if 'Score' in df.columns:\n",
        "        plt.figure(figsize=(8,5))\n",
        "        sns.histplot(df['Score'].dropna(), bins=30, kde=True)\n",
        "        plt.title(\"Score Distribution\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, \"score_distribution.png\"), dpi=150)\n",
        "        plt.close()\n",
        "    # Boxplot: Score by SchoolType if available\n",
        "    if 'SchoolType' in df.columns and 'Score' in df.columns:\n",
        "        plt.figure(figsize=(7,4))\n",
        "        sns.boxplot(x='SchoolType', y='Score', data=df)\n",
        "        plt.title(\"Score by School Type\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, \"score_by_schooltype.png\"), dpi=150)\n",
        "        plt.close()\n",
        "    # Correlation heatmap for numeric columns\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if len(num_cols) >= 2:\n",
        "        plt.figure(figsize=(8,6))\n",
        "        sns.heatmap(df[num_cols].corr(), annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
        "        plt.title(\"Correlation Heatmap (numeric)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, \"correlation_heatmap.png\"), dpi=150)\n",
        "        plt.close()\n",
        "def prepare_features(df, drop_id=True):\n",
        "    # Drop StudentID-like column if exists (to avoid leakage)\n",
        "    candidate_id_cols = [c for c in df.columns if c.lower() in ('studentid', 'student_id', 'id')]\n",
        "    if candidate_id_cols and drop_id:\n",
        "        df = df.drop(columns=candidate_id_cols)\n",
        "    # Remove target if present (we'll separate later)\n",
        "    # Convert categorical columns to dummies (one-hot)\n",
        "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "    # Exclude text columns that are long (if any) â€” but we'll convert all strings\n",
        "    df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
        "    return df_encoded\n",
        "def train_random_forest(X, y):\n",
        "    # Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "    # Scale numeric columns only\n",
        "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = X_train.copy()\n",
        "    X_test_scaled = X_test.copy()\n",
        "    if numeric_cols:\n",
        "        X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "        X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
        "    # Train RF\n",
        "    clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nModel Accuracy: {acc:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    # Save confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, \"confusion_matrix.png\"), dpi=150)\n",
        "    plt.close()\n",
        "    return clf, X_test, y_test, y_pred\n",
        "\n",
        "def feature_importance_plot(model, X, top_n=15):\n",
        "    # Try to get feature importances; if model has it\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "        importances_top = importances.head(top_n)\n",
        "        plt.figure(figsize=(8,6))\n",
        "        sns.barplot(x=importances_top.values, y=importances_top.index)\n",
        "        plt.title(\"Top Feature Importances\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, \"feature_importances.png\"), dpi=150)\n",
        "        plt.close()\n",
        "        # Save importances to CSV\n",
        "        importances.to_csv(os.path.join(OUTPUT_DIR, \"feature_importances.csv\"))\n",
        "    else:\n",
        "        print(\"Model does not expose feature_importances_\")\n",
        "\n",
        "def main():\n",
        "    safe_mkdir(OUTPUT_DIR)\n",
        "    try:\n",
        "        df = load_data(DATA_FILE)\n",
        "    except Exception as e:\n",
        "        print(\"ERROR loading data:\", e)\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(\"Loaded dataset with shape:\", df.shape)\n",
        "    # quick columns preview\n",
        "    print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "    # Clean missing and duplicates\n",
        "    df = clean_and_fill(df)\n",
        "\n",
        "    # Infer target (Pass) from Score or existing Pass\n",
        "    try:\n",
        "        df, target_col = infer_target(df)\n",
        "        print(f\"Using target column: '{target_col}'\")\n",
        "    except Exception as e:\n",
        "        print(\"ERROR inferring target:\", e)\n",
        "        print(\"If your CSV has a different target column, add it named 'Pass' (0/1) or add a 'Score' column.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # EDA\n",
        "    basic_eda_and_save(df)\n",
        "\n",
        "    # Prepare features\n",
        "    # Keep a copy of cleaned df for saving\n",
        "    df_cleaned_path = os.path.join(OUTPUT_DIR, \"cleaned_student_data.csv\")\n",
        "    df.to_csv(df_cleaned_path, index=False)\n",
        "    print(f\"Cleaned data saved to: {df_cleaned_path}\")\n",
        "\n",
        "    # Encode features\n",
        "    y = df[target_col]\n",
        "    X_df = df.drop(columns=[target_col], errors='ignore')\n",
        "    X_encoded = prepare_features(X_df, drop_id=True)\n",
        "\n",
        "    # Ensure no constant columns, drop columns with single unique value\n",
        "    nunique = X_encoded.nunique()\n",
        "    cols_to_drop = nunique[nunique <= 1].index.tolist()\n",
        "    if cols_to_drop:\n",
        "        X_encoded.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "    # Align X and y shapes\n",
        "    print(\"Final feature matrix shape:\", X_encoded.shape)\n",
        "\n",
        "    if X_encoded.shape[0] < 10:\n",
        "        print(\"Not enough rows to train a model. Need more data.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Train model\n",
        "    model, X_test, y_test, y_pred = train_random_forest(X_encoded, y)\n",
        "\n",
        "    # Feature importance\n",
        "    feature_importance_plot(model, X_encoded)\n",
        "    try:\n",
        "        X_test_reset = X_test.reset_index(drop=True)\n",
        "        results_df = X_test_reset.copy()\n",
        "        results_df['Actual'] = y_test.reset_index(drop=True)\n",
        "        results_df['Predicted'] = y_pred\n",
        "        results_df.to_csv(os.path.join(OUTPUT_DIR, \"predictions_sample.csv\"), index=False)\n",
        "        print(\"Saved predictions sample to outputs/predictions_sample.csv\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not save predictions sample:\", e)\n",
        "\n",
        "    print(\"\\nDone. Check the 'outputs' folder for images and CSV files.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}